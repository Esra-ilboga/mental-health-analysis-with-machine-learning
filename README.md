# Makine Ã–ÄŸrenmesi Ä°le Ruh SaÄŸlÄ±ÄŸÄ± Analizi 
Beslenme bilgilerinin, vÃ¼cut aÄŸÄ±rlÄ±ÄŸÄ±nÄ±n ve enerji seviyesinin, ruh hali Ã¼zerindeki etkisi analiz edilmek Ã¼zere bu proje geliÅŸitirilmiÅŸtir. KullanÄ±lan veri setine [buradan](https://www.kaggle.com/datasets/inpursuitofnothing/nutrition-vs-weight-mood-energy-dataset) eriÅŸebilirsiniz. Bu projede kullanÄ±lan makine Ã¶ÄŸrenmesi algoritmalarÄ±ndan ikisi Supervised Learning algoritmalarÄ±ndan  Linear Regression ve Random Forest, diÄŸer ikisi de Unsupervised Learning algoritmalarÄ±ndan K-Means ve PCA'dÄ±r. Gerekli analizlerin yapÄ±lmasÄ± iÃ§in makine Ã¶ÄŸrenmesi algoritmalarÄ±ndan Ã¶nce data processing(veri iÅŸleme)  gerÃ§ekleÅŸtirilmiÅŸtir.
## Ä°Ã§indekiler

1. [Veri Seti HakkÄ±nda Bilgi](#1-veri-seti-hakkÄ±nda-bilgi)
2. [Gerekli KÃ¼tÃ¼phaneleri Dahil Etme](#2-gerekli-kÃ¼tÃ¼phaneleri-dahil-etme)
3. [Veri YÃ¼kleme ve GÃ¶rÃ¼ntÃ¼leme](#3-veri-yÃ¼kleme-ve-gÃ¶rÃ¼ntÃ¼leme)
4. [Veri Setini Anlama ve Ä°ÅŸleme](#4-veri-setini-anlama-ve-iÅŸleme)
5. [Veri GÃ¶rselleÅŸtirme](#5-veri-gÃ¶rselleÅŸtirme)
6. [Korelasyon Matrisi](#6-korelasyon-matrisi)
7. [Makine Ã–ÄŸrenmesi Modellerinin EÄŸitimi ve SkorlarÄ±](#7-makine-Ã¶ÄŸrenmesi-modellerinin-eÄŸitimi-ve-skorlarÄ±)
8. [Skor DeÄŸerlendirmesi ve DoÄŸruluk OranÄ± ArtÄ±rma YÃ¶ntemleri](#8-skor-deÄŸerlendirmesi-ve-doÄŸruluk-oranÄ±-arttÄ±rma-yÃ¶ntemleri)
9. [Kodun Ä°ÅŸileyiÅŸini AÃ§Ä±klayan Video](#9-kodun-iÅŸleyiÅŸini-aÃ§Ä±klayan-video)
10. [Sertifikalar](#10-sertifikalar)

## 1. Veri Seti HakkÄ±nda Bilgi
Veri seti, 9 sÃ¼tun ve 100000 satÄ±rdan oluÅŸmaktadÄ±r. Bu sÃ¼tunlar; **Product Name** , **Calories** , **Body Type** , **Mood** , **Energy**, **Total Fat** , **Total Sugars**, **Carbohydrates (Carbs)** ve **Protein**'dir. Bu sÃ¼tunlar aÅŸaÄŸÄ±daki tabloda detaylandÄ±rÄ±lmÄ±ÅŸtÄ±r:

| **SÃ¼tun AdÄ±**              | **Veri Tipi** | **AÃ§Ä±klama**                                                                  |
|----------------------------|---------------|--------------------------------------------------------------------------------|
| `Product Name`             | Kategorik     | ÃœrÃ¼n Ä°simleri.                                                                |
| `Calories`                 | SayÄ±sal       | ÃœrÃ¼nÃ¼n kalori miktarÄ±.                                                        |
| `Body Type`                | Kategorik     | Ä°nsan vÃ¼cut aÄŸÄ±rlÄ±ÄŸÄ± ('Fat', 'Balanced', 'Slim').                             |
| `Mood`                     | Kategorik     | Ä°nsan ruh hali (modu) ('Neutral', 'Sad', 'Happy').                            |
| `Energy`                   | Kategorik     | Enerji miktarÄ± ('Energy Burst', 'Low', 'Normal').                             |
| `Total Fat`                | Kategorik     | Toplam yaÄŸ (g cinsinden).                                                     |
| `Total Sugars`             | Kategorik     | Toplam ÅŸeker (g cinsinden).                                                   |
| `Carbohydrates (Carbs)`    | Kategorik     | Karbonhidrat miktarÄ± (g cinsinden).                                           |
| `Protein`                  | Kategorik     | Protein miktarÄ± (g cinsinden).                                                |

## 2. Gerekli KÃ¼tÃ¼phaneleri Dahil Etme
Projede veriyi iÅŸlemek, algoritmalarÄ± uygulamak, doÄŸruluk deÄŸerlendirmelerini yapmak ve gÃ¶rselleÅŸtirmeler yapabilmek iÃ§in bazÄ± kÃ¼tÃ¼phaneler dahil etmeliyiz. 

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from imblearn.over_sampling import SMOTE
from sklearn.datasets import load_iris
from sklearn.impute import SimpleImputer
from sklearn.metrics import silhouette_score
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
```

## 3. Veri YÃ¼kleme ve GÃ¶rÃ¼ntÃ¼leme
Veriyi projeye dahil etmek ve gÃ¶rÃ¼ntÃ¼lemek iÃ§in aÅŸaÄŸÄ±daki kodlar yazÄ±lÄ±r:
```python
# Veri seti yÃ¼kleme
data = pd.read_csv('nutrition_labels.csv')

# Veri setinin ilk beÅŸ satÄ±rÄ±nÄ± tablo halinde gÃ¶rme 
data.head()

# Veriler hakkÄ±nda detaylÄ± bilgi alma
data.info()

# null deÄŸerler var mÄ±? kÃ¶ntrolÃ¼nÃ¼ saÄŸlar
data.isnull().sum()
```
### Ekran GÃ¶rÃ¼ntÃ¼leri 
![Verisetibilgi](https://github.com/user-attachments/assets/387eeee8-a361-472e-898b-eb4c95227c1b)

## 4. Veri Setini Anlama ve Ä°ÅŸleme
Verileri anladÄ±ktan sonra bu verileri istenen ÅŸekilde yani daha kullanÄ±labilir hale getirmek gerekmektedir. Eksik veriler silinmeli veyahut eksik verileri bulunduklarÄ± sÃ¼tundaki verilerin medyanÄ±yla doldurmalÄ±yÄ±z. Object(kategorik) veriler sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmeli. Veri dengesizlikleri varsa veriler dengeli hale getirilmeli. Gereksiz sÃ¼tunlar varsa Ã§Ä±karÄ±lmalÄ±.AÅŸaÄŸÄ±da bu iÅŸlemleri gerÃ§ekleÅŸtirdiÄŸim kodlar yazmaktadÄ±r:
```python
# Veri setindeki eksik deÄŸerleri, sÃ¼tunlarÄ±n medyan deÄŸerleriyle doldurur.
data_filled = data.fillna(data.median())
#---------------------------------------------------------------
# Belirtilen sÃ¼tunlardaki deÄŸerlerden 'g' harfini kaldÄ±rÄ±r ve veriyi float tÃ¼rÃ¼ne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
for column in ["Total Fat", "Total Sugars", "Carbohydrates (Carbs)", "Protein"]:
    data[column] = data[column].str.replace("g", "").astype(float)
#---------------------------------------------------------------
# 'Product Name' sÃ¼tununu veri setinden Ã§Ä±karÄ±r, her satÄ±r iÃ§in benzersiz bir 'Product ID' oluÅŸturur
# ve 'Product ID' sÃ¼tununu veri setinin ilk sÃ¼tunu olacak ÅŸekilde yeniden sÄ±ralar.
data = data.drop("Product Name", axis=1)
data["Product ID"] = range(1, len(data) + 1)
data = data[["Product ID"] + [col for col in data.columns if col != "Product ID"]]
print("Yeni Veri Seti:")
print(data)
#---------------------------------------------------------------
data = pd.DataFrame(data)

# Kategorik sÃ¼tunlarÄ± seÃ§me
categorical_columns = data.select_dtypes(include=['object']).columns

# One-Hot Encoding uygulama ve veri Ã§erÃ§evesini gÃ¼ncelleme
data = pd.get_dummies(data, columns=categorical_columns)

boolean_columns = data.select_dtypes(include=['bool']).columns
for column in boolean_columns:
    data[column] = data[column].astype(int)

# GÃ¼ncellenmiÅŸ veri setini gÃ¶rÃ¼ntÃ¼leme
data.head()
#--------------------------------------------------------------
data = pd.DataFrame(data)

# Ruh saÄŸlÄ±ÄŸÄ± sÃ¼tununu oluÅŸturma
data["Mental_Health"] = ((data["Mood_Happy"] == 1) | (data["Mood_Neutral"] == 1)).astype(int)
#---------------------------------------------------------------
# 'Mood_Happy', 'Mood_Neutral' ve 'Mood_Sad' sÃ¼tunlarÄ±nÄ± veri setinden kaldÄ±rÄ±r 
# Ã§Ã¼nkÃ¼ bu sÃ¼tunlardaki bilgiler daha Ã¶nce 'Mental_Health' sÃ¼tununda Ã¶zetlenmiÅŸtir.
data = data.drop(columns=["Mood_Happy", "Mood_Neutral", "Mood_Sad"])
data.head()
#--------------------------------------------------------------
# 'Product ID' sÃ¼tununu veri setinden kaldÄ±rÄ±r 
# Ã§Ã¼nkÃ¼ bu sÃ¼tun analiz veya modelleme iÃ§in gerekli deÄŸildir.
data.drop(columns=['Product ID'], inplace=True)
#--------------------------------------------------------------
# 'Mental_Health' sÃ¼tunundaki sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± normalleÅŸtirilmiÅŸ olarak hesaplar
# ve bu daÄŸÄ±lÄ±mÄ± yazdÄ±rÄ±r.
class_distribution = data['Mental_Health'].value_counts(normalize=True)
print("Ruh saÄŸlÄ±ÄŸÄ± oranlarÄ±: ")
print(class_distribution)

# 'Mental_Health' sÃ¼tunundaki sÄ±nÄ±flarÄ±n gÃ¶rsel olarak daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶steren bir countplot Ã§izer.
plt.figure(figsize=(8, 6))
sns.countplot(x='Mental_Health', data=data)
plt.title("Ruh saÄŸlÄ±ÄŸÄ± daÄŸÄ±lÄ±mÄ±")
plt.show()
#--------------------------------------------------------------
# BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri ayÄ±r
X = data.drop('Mental_Health', axis=1)
y = data['Mental_Health']

# SMOTE ile oversampling
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# Yeni sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± kontrol et
print("Yeni Ruh SaÄŸlÄ±ÄŸÄ± DaÄŸÄ±lÄ±mÄ±:")
print(y_resampled.value_counts())
```
### Ä°lgili GÃ¶rseller ve Veri Seti Son HAli
![veridengesizliÄŸi](https://github.com/user-attachments/assets/4ed4bb48-6454-402a-99c6-cdb8f9338338)</br>
![datasonhal](https://github.com/user-attachments/assets/be6886a5-cb24-4385-b75b-26c466dc2deb)

## 5. Veri GÃ¶rselleÅŸtirme
Verileri gÃ¶rselleÅŸtirmek iÃ§in histogram ve boxplot kullanÄ±ldÄ±. GÃ¶rÃ¼ntÃ¼leri aÅŸaÄŸÄ±da verilmiÅŸtir.
### Histogramlar
![histogram](https://github.com/user-attachments/assets/a3f0f4b5-f0b3-46d0-bfa7-f7cd755aebf8)
### Boxplot
![boxplot](https://github.com/user-attachments/assets/1f5f0a54-66a4-49a3-be7a-be7a3efd1e26)

## 6. Korelasyon Matrisi
![korelasyon](https://github.com/user-attachments/assets/d750f848-95d5-4dce-8ce9-d8a2c78b2653)

## 7. Makine Ã–ÄŸrenmesi Modellerinin EÄŸitimi ve SkorlarÄ±
AÅŸaÄŸÄ±da adÄ±m adÄ±m uygulanan algoritmalar kendi baÅŸlÄ±klarÄ± altÄ±nda verilmiÅŸtir.</br>
### Random Forest
Random Forest, karar aÄŸaÃ§larÄ±ndan (decision trees) oluÅŸan bir topluluk yÃ¶ntemidir. Birden fazla karar aÄŸacÄ± eÄŸitilir ve sonuÃ§lar oylama (sÄ±nÄ±flandÄ±rma) veya ortalama (regresyon) yÃ¶ntemiyle birleÅŸtirilir. Bu algoritmayÄ± kullanarak aÅŸaÄŸÄ±daki kod bloÄŸu yazÄ±ldÄ±: 
```python
# BaÄŸÄ±mlÄ± ve baÄŸÄ±msÄ±z deÄŸiÅŸkenlerin ayrÄ±lmasÄ±
X = data.drop(columns=["Mental_Health"])
y = data["Mental_Health"]

# EÄŸitim ve test setine bÃ¶lme
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Random Forest Modeli
rf = RandomForestClassifier()
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

# Performans DeÄŸerlendirmesi
print("Random Forest")
print(classification_report(y_test, y_pred_rf))
```
+ kodun Ã§Ä±ktÄ±sÄ± aÅŸaÄŸÄ±daki gÃ¶rselde verilmiÅŸtir.
![random](https://github.com/user-attachments/assets/1adb4514-7688-4080-b184-7857fc311eab)

### Linear Regression
Lineer regresyon, baÄŸÄ±mlÄ± bir deÄŸiÅŸken (y) ile bir veya daha fazla baÄŸÄ±msÄ±z deÄŸiÅŸken (x) arasÄ±ndaki doÄŸrusal iliÅŸkiyi modellemek iÃ§in kullanÄ±lan bir yÃ¶ntemdir.  Bu algoritmayÄ± kullanarak aÅŸaÄŸÄ±daki kod bloÄŸu yazÄ±ldÄ±: 
```python
# BaÄŸÄ±mlÄ± ve baÄŸÄ±msÄ±z deÄŸiÅŸkenlerin ayrÄ±lmasÄ±
X = data.drop(columns=["Mental_Health"])
y = data["Mental_Health"]

# EÄŸitim ve test setine bÃ¶lme
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Linear Regression Modeli
lr = LinearRegression()
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)
# Performans DeÄŸerlendirmesi
mse = mean_squared_error(y_test, y_pred_lr)
r2 = r2_score(y_test, y_pred_lr)
print("Linear Regression")
print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
```
+ kodun Ã§Ä±ktÄ±sÄ± gÃ¶rselde verilmiÅŸtir.
![lineer](https://github.com/user-attachments/assets/6f2f5569-a775-49e7-98ad-d993dfd51a59)

### K-Means
 K-Means, bir veri setini Ã¶nceden belirlenmiÅŸ ğ¾ sayÄ±da kÃ¼meye ayÄ±ran bir kÃ¼meleme algoritmasÄ±dÄ±r. Her bir nokta, en yakÄ±n kÃ¼me merkezine (centroid) atanÄ±r. Bu algoritma iÃ§in Ã¶ncelikle uygun kÃ¼me sayÄ±sÄ± bulunmak iÃ§in aÅŸaÄŸÄ±daki kod bloÄŸu yazÄ±ldÄ±: 
 ```python
scaler = StandardScaler()
scaled_data = scaler.fit_transform(data)

inertias = []
silhouettes = []
# Burdaki range deÄŸerleri sÄ±rasÄ±yla (10, 20), (21, 31), (40, 80) ÅŸekilne denendi
for k in range(10, 20):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(scaled_data)
    inertias.append(kmeans.inertia_)
    silhouettes.append(silhouette_score(scaled_data, kmeans.labels_))

# Grafikleri Ã§izdirme
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(range(10, 20), inertias, marker='o')
plt.title("Elbow Method")
plt.xlabel("KÃ¼me SayÄ±sÄ±")
plt.ylabel("Inertia")

plt.subplot(1, 2, 2)
plt.plot(range(10, 20), silhouettes, marker='o')
plt.title("Silhouette Analysis")
plt.xlabel("KÃ¼me SayÄ±sÄ±")
plt.ylabel("Silhouette Score")
plt.show()
```
ArdÄ±ndan uygun K (kÃ¼me sayÄ±sÄ±) deÄŸeri 11 olarak belirlendi ve ona gÃ¶re aÅŸaÄŸÄ±daki kod bloÄŸu uygulandÄ±: 
```python
# Veri Ã¶n iÅŸleme (Ã¶lÃ§ekleme)
scaler = StandardScaler()
scaled_data = scaler.fit_transform(data)

# K-Means modelini eÄŸitme
kmeans = KMeans(n_clusters=11, random_state=42)  # KÃ¼me sayÄ±sÄ±: 11
kmeans.fit(scaled_data)

# KÃ¼melere atanan etiketler
data["Cluster"] = kmeans.labels_

#  Performans analizi
# a) Inertia (toplam hata kareleri toplamÄ±)
inertia = kmeans.inertia_

# b) Silhouette Score (kÃ¼melerin ayÄ±rt edilebilirliÄŸi)
silhouette_avg = silhouette_score(scaled_data, kmeans.labels_)

# SonuÃ§larÄ± gÃ¶rÃ¼ntÃ¼leme
print("KÃ¼meleme SonuÃ§larÄ±:")
print(data)
print("\nPerformans Analizi:")
print(f"Inertia (Hata Kareleri ToplamÄ±): {inertia:.2f}")
print(f"Silhouette Score: {silhouette_avg:.2f}")
```
+ KodlarÄ±n Ã§Ä±ktÄ±sÄ± aÅŸaÄŸÄ±daki verilmiÅŸtir.
![kume1](https://github.com/user-attachments/assets/5ec4f106-d652-4bd3-99fe-123146963cc2)</br>
![kume2](https://github.com/user-attachments/assets/837105b6-fc42-40ab-a4fd-f8b6ef2e1321)</br>
![kume3](https://github.com/user-attachments/assets/572c6fe9-4e19-4d44-b079-4984033b2945)</br>
![performanss](https://github.com/user-attachments/assets/79315384-9256-4867-addf-321626bb3465)

### PCA 
PCA, yÃ¼ksek boyutlu veriyi daha dÃ¼ÅŸÃ¼k boyutlara indirerek ana bileÅŸenleri (principal components) Ã§Ä±karan bir boyut indirgeme yÃ¶ntemidir. Verideki deÄŸiÅŸkenlik (varyans) korunmaya Ã§alÄ±ÅŸÄ±lÄ±r.  Bu algoritmayÄ± kullanarak aÅŸaÄŸÄ±daki kod bloÄŸu yazÄ±ldÄ±: 
```python
#  Veriyi Ã–lÃ§eklendirme (StandartlaÅŸtÄ±rma)
scaler = StandardScaler()
scaled_data = scaler.fit_transform(data)

#  PCA AlgoritmasÄ±nÄ± Uygulama
pca = PCA(n_components=None)  # TÃ¼m bileÅŸenleri Ã§Ä±kar
pca_data = pca.fit_transform(scaled_data)

#  Performans Analizi - AÃ§Ä±klanan Varyans OranÄ±
explained_variance_ratio = pca.explained_variance_ratio_
cumulative_variance_ratio = np.cumsum(explained_variance_ratio)

#  AÃ§Ä±klanan Varyans OranÄ±nÄ± GÃ¶rselleÅŸtirme
plt.figure(figsize=(10, 6))
plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, alpha=0.7, align='center', label='Individual Variance')
plt.step(range(1, len(cumulative_variance_ratio) + 1), cumulative_variance_ratio, where='mid', label='Cumulative Variance')
plt.xlabel('Temel BileÅŸen Ä°ndeksi')
plt.ylabel('AÃ§Ä±klanan Varyans OranÄ±')
plt.title('Temel BileÅŸenlere GÃ¶re AÃ§Ä±klanan Varyans')
plt.legend(loc='best')
plt.grid(True)
plt.show()

#  En Ã–nemli BileÅŸenleri Belirleme
# Ã–rneÄŸin, %95 aÃ§Ä±klanan varyansa ulaÅŸmak iÃ§in gereken bileÅŸen sayÄ±sÄ±
n_components_95 = np.argmax(cumulative_variance_ratio >= 0.95) + 1
print(f"%95 varyansÄ± aÃ§Ä±klamak iÃ§in gerekli bileÅŸen sayÄ±sÄ±: {n_components_95}")

#  PCA ile DÃ¼ÅŸÃ¼k Boyutlu Veriyi Elde Etme
# %95 varyansÄ± aÃ§Ä±klayan bileÅŸenlerle yeniden PCA uygula
pca_optimized = PCA(n_components=n_components_95)
reduced_data = pca_optimized.fit_transform(scaled_data)

#  SonuÃ§larÄ± GÃ¶rselleÅŸtirme (2D Ã–rneÄŸi)
if n_components_95 >= 2:
    plt.figure(figsize=(8, 6))
    plt.scatter(reduced_data[:, 0], reduced_data[:, 1], alpha=0.7, cmap='viridis')
    plt.title('PCA DÃ¼ÅŸÃ¼k Boyutlu GÃ¶rselleÅŸtirme (2 BileÅŸen)')
    plt.xlabel('Birinci Temel BileÅŸen')
    plt.ylabel('Ä°kinci Temel BileÅŸen')
    plt.grid(True)
    plt.show()
```
+ kodun Ã§Ä±ktÄ±sÄ± aÅŸaÄŸÄ±daki gÃ¶rselde verilmiÅŸtir.
![PCA1](https://github.com/user-attachments/assets/349cb897-b965-458e-ac69-3ee5762f09c2)</br>
![PCA2](https://github.com/user-attachments/assets/4fc7f261-a6ff-4872-8f3a-967548436995)

Bu algoritmanÄ±n performans deÄŸerlendirmesi iÃ§in AÅŸaÄŸÄ±daki iki kod yazÄ±ldÄ±:
```python
# Orijinal boyuta yeniden yapÄ±landÄ±rma
reconstructed_data = pca_optimized.inverse_transform(reduced_data)

# Yeniden yapÄ±landÄ±rma hatasÄ± (Mean Squared Error)
reconstruction_error = np.mean((scaled_data - reconstructed_data) ** 2)
print(f"Yeniden YapÄ±landÄ±rma HatasÄ±: {reconstruction_error:.4f}")
#--------------------------------------------------------------
# KÃ¼meleme
kmeans = KMeans(n_clusters=11, random_state=42)
kmeans.fit(reduced_data)
labels = kmeans.labels_

# Silhouette Score hesaplama
silhouette_avg = silhouette_score(reduced_data, labels)
print(f"Silhouette Score: {silhouette_avg:.2f}")
```
+ kodun Ã§Ä±ktÄ±larÄ± gÃ¶rselde verilmiÅŸtir.
![PCA4](https://github.com/user-attachments/assets/d0101922-4ba9-4e53-9f63-dcb5912e9a4b)
![PCA5](https://github.com/user-attachments/assets/68cb3d79-dae7-40a9-9314-b8adb9c35f91)

## 8.Skor DeÄŸerlendirmesi ve DoÄŸruluk OranÄ± ArtÄ±rma YÃ¶ntemleri
### Linear Regression Performans DeÄŸerlendirmesi
#### Performans
Mean Squared Error (MSE) 0.0829, modelin tahminleri ile gerÃ§ek deÄŸerler arasÄ±ndaki farklarÄ±n karesinin ortalamasÄ±nÄ±n dÃ¼ÅŸÃ¼k olduÄŸunu, ancak hala hata olduÄŸunu gÃ¶steriyor. R-squared (RÂ²) deÄŸeri ise 0.4777, modelin verinin %47.77'sini doÄŸru tahmin edebildiÄŸini belirtir, bu da doÄŸrusal regresyon iÃ§in ortalama bir performansÄ± ifade eder ve daha iyi sonuÃ§lar elde edilebileceÄŸini gÃ¶sterir.
#### Yorum
Linear Regression, verinin doÄŸrusal iliÅŸkilerini Ã¶ÄŸrenme konusunda baÅŸarÄ±lÄ± olsa da, RÂ² deÄŸeri, modelin yeterince gÃ¼Ã§lÃ¼ olmadÄ±ÄŸÄ±na iÅŸaret ediyor. Bu nedenle, doÄŸrusal iliÅŸkilerin gÃ¼Ã§lÃ¼ olduÄŸu veri setlerinde bile daha iyi sonuÃ§lar elde edilebilir.
### Random Forest Performans DeÄŸerlendirmesi
#### Performans
Modelin Precision, Recall, F1-Score ve Accuracy deÄŸerleri tÃ¼m sÄ±nÄ±flar iÃ§in 1.00 olup, bu da modelin her iki sÄ±nÄ±fÄ± da tamamen doÄŸru ÅŸekilde sÄ±nÄ±flandÄ±rdÄ±ÄŸÄ±nÄ± ve yanlÄ±ÅŸ pozitif ya da yanlÄ±ÅŸ negatif oranlarÄ±nÄ± sÄ±fÄ±ra yakÄ±n tuttuÄŸunu gÃ¶sterir. AyrÄ±ca, Accuracy'nin %100 olmasÄ±, modelin tÃ¼m tahminlerinde mÃ¼kemmel bir performans sergilediÄŸini belirtir.
#### Yorum
 Random Forest modeli burada mÃ¼kemmel bir performans sergiliyor. Precision, recall ve F1-score deÄŸerlerinin yÃ¼ksekliÄŸi, modelin her iki sÄ±nÄ±fÄ± da doÄŸru bir ÅŸekilde tahmin ettiÄŸini ve   1.00'lÄ±k sonuÃ§larÄ± bazen gerÃ§ek dÃ¼nya verilerinde overfittingâ€™e iÅŸaret edebileceÄŸini gÃ¶steriyor bu nedenle modelin test verisiyle doÄŸrulanmasÄ± Ã¶nemlidir
 ### K-Means Performans DeÄŸerlendirmesi
#### Performans
K-Means algoritmasÄ±nÄ±n Inertia deÄŸeri 435330.75, kÃ¼melerin iÃ§indeki Ã¶rneklerin merkezine olan mesafelerin karesinin toplamÄ±nÄ±n yÃ¼ksek olduÄŸunu ve bu durumun kÃ¼meleme kalitesinin dÃ¼ÅŸÃ¼k olduÄŸunu gÃ¶steriyor. Silhouette Score ise 0.27, kÃ¼meler arasÄ±ndaki ayrÄ±mÄ±n zayÄ±f olduÄŸunu ve kÃ¼meleme kalitesinin yetersiz olduÄŸunu iÅŸaret eder, bu da modelin baÅŸarÄ±lÄ± olmadÄ±ÄŸÄ±na dair bir gÃ¶sterge sunar.
#### Yorum
K-Means'in inertia deÄŸeri ve dÃ¼ÅŸÃ¼k Silhouette Score deÄŸeri, modelin veri setindeki yapÄ±yÄ± Ã§ok iyi Ã¶ÄŸrenmediÄŸini ve kÃ¼meler arasÄ±nda net ayrÄ±mlar oluÅŸturmakta zorlandÄ±ÄŸÄ±nÄ± gÃ¶steriyor. Bu durumda, K-Means algoritmasÄ± daha iyi sonuÃ§lar verebilmesi iÃ§in parametre ayarlarÄ±na veya baÅŸka bir kÃ¼meleme algoritmasÄ±na ihtiyaÃ§ duyabilir.
### PCA Performans DeÄŸerlendirmesi
#### Performans
PCA modelinin Yeniden YapÄ±landÄ±rma HatasÄ± 0.0335, boyut indirgeme iÅŸlemi sonrasÄ± orijinal verilere oldukÃ§a yakÄ±n bir temsil oluÅŸturulduÄŸunu ancak biraz bilgi kaybÄ± yaÅŸandÄ±ÄŸÄ±nÄ± gÃ¶steriyor. Silhouette Score'un 0.24 olmasÄ±, PCA'nÄ±n elde edilen dÃ¼ÅŸÃ¼k boyutlu verilere uygun bir ÅŸekilde kÃ¼meleme yapmada etkili olmadÄ±ÄŸÄ±nÄ± ve kÃ¼meleme kalitesinin dÃ¼ÅŸÃ¼k olduÄŸunu iÅŸaret eder.
#### Yorum 
PCA, veriyi daha dÃ¼ÅŸÃ¼k boyutlarda temsil etmede baÅŸarÄ±lÄ± olsa da, dÃ¼ÅŸÃ¼k Silhouette Score deÄŸeri, boyut indirgeme iÅŸleminden sonra kÃ¼meler arasÄ±nda Ã§ok belirgin bir ayrÄ±m olmadÄ±ÄŸÄ±nÄ± gÃ¶steriyor. Bu, PCA'nÄ±n daha Ã§ok veriyi gÃ¶rselleÅŸtirme veya Ã¶zellik seÃ§imi iÃ§in kullanÄ±lmasÄ± gerektiÄŸini gÃ¶steriyor.
### Genel SonuÃ§ ve DeÄŸerlendirme
Random Forest, yÃ¼ksek precision, recall, F1-score ve accuracy deÄŸerleriyle mÃ¼kemmel bir sÄ±nÄ±flandÄ±rma baÅŸarÄ±sÄ± sergileyerek bu dÃ¶rt algoritma arasÄ±nda en iyi performansÄ± gÃ¶steriyor. Linear Regression, doÄŸrusal olmayan verilerle Ã§alÄ±ÅŸÄ±rken sÄ±nÄ±rlÄ± bir performans sergileyip RÂ²'nin 0.4777 olmasÄ±yla yalnÄ±zca veri setinin yarÄ±sÄ±ndan biraz fazlasÄ±nÄ± aÃ§Ä±klayabiliyor. K-Means, dÃ¼ÅŸÃ¼k Silhouette Score deÄŸeriyle kÃ¼melenmiÅŸ veri setlerinde baÅŸarÄ±lÄ± olamayarak parametre ayarlarÄ±nÄ±n ya da farklÄ± bir kÃ¼meleme yÃ¶nteminin gerekebileceÄŸini gÃ¶steriyor. PCA ise boyut indirgeme ve gÃ¶rselleÅŸtirme iÃ§in faydalÄ± olsa da kÃ¼meleme baÅŸarÄ±sÄ± sÄ±nÄ±rlÄ±dÄ±r. 
Bu verilere dayanarak Random Forest algoritmasÄ±, diÄŸerlerinden Ã§ok daha iyi sonuÃ§lar veriyor ve en iyi performansÄ± sergileyen modeldir.

## 9. Kodun Ä°ÅŸileyiÅŸini AÃ§Ä±klayan Video
Projeyi kÄ±saca aÃ§Ä±kladÄ±ÄŸÄ±m youtube videosuna eriÅŸmek iÃ§in [YotubeLinki](https://youtu.be/72kCtWODcto) yazan yere tÄ±klayÄ±nÄ±z.

## 10. Sertifikalar











